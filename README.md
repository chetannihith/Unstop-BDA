```markdown
# Big Data Analytics on Unstop Data

This repository contains the code and resources for a comprehensive project on **Big Data Analytics**. The project involves data scraping, preprocessing, creating visualizations, and applying analytics techniques to analyze hackathons, internships, and job datasets scraped from the Unstop platform.

## ğŸš€ Project Features
- **Data Preprocessing**: Cleaned and prepared datasets for analysis.
- **Visualizations**: Created critical visualizations to derive insights.
- **Analytics Applications**: Applied various analytics techniques to uncover hidden patterns.
- **Cross-Dataset Insights**: Combined datasets to generate deeper insights.

---

## ğŸ“‚ Repository Structure

```plaintext
Unstop-BDA
â”‚
â”œâ”€â”€ Preprocessed_files
â”‚   â”œâ”€â”€ cleaned_hackathons.csv
â”‚   â”œâ”€â”€ cleaned_internship.csv
â”‚   â”œâ”€â”€ cleaned_jobs.csv
â”‚   â”œâ”€â”€ hackathon_clean.ipynb
â”‚   â”œâ”€â”€ internship_clean.ipynb
â”‚   â””â”€â”€ jobs_clean.ipynb
â”‚
â”œâ”€â”€ Project_files
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ main.ipynb
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Scraping_files
â”‚   â”œâ”€â”€ scrape_unstop_hackathon.py
â”‚   â”œâ”€â”€ scrape_unstop_internship.py
â”‚   â””â”€â”€ scrape_unstop_job.py
â”‚   â”œâ”€â”€ scraped_hackathons.csv
â”‚   â”œâ”€â”€ scraped_internships.csv
â”‚   â””â”€â”€ scraped_jobs.csv
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“Š Datasets

### Hackathons
- **Columns**: Category, Eligibility, Applied, Impressions, Deadline, etc.
- **Insights**: Trends in categories, application patterns, and deadlines.

### Internships
- **Columns**: Position, Company, Eligibility, Impressions, Applied, etc.
- **Insights**: Popular internship domains, top companies, and application trends.

### Jobs
- **Columns**: Position, Eligibility, Impressions, Applied, etc.
- **Insights**: Popular job roles, application vs. impressions patterns.

---

## ğŸ› ï¸ Steps to Run

### 1. Clone the Repository
```bash
git clone https://github.com/chetannihith/Unstop-BDA.git
```

### 2. Install Dependencies
Navigate to the repository folder and install the required Python libraries using:
```bash
pip install -r requirements.txt
```

### 3. Run Notebooks or Scripts
Use Jupyter notebooks or directly execute Python scripts:
- **Preprocessing**: `Preprocessed_files/hackathon_clean.ipynb`, `Preprocessed_files/internship_clean.ipynb`, or `Preprocessed_files/jobs_clean.ipynb`
- **Scraping**: `Scraping_files/scrape_unstop_hackathon.py`, `Scraping_files/scrape_unstop_internship.py`, or `Scraping_files/scrape_unstop_job.py`
- **Visualization**: `Project_files/main.ipynb`
- **Streamlit App**: Create a Streamlit website using `app.py`
  ```bash
  streamlit run Project_files/app.py
  ```

---

## ğŸ“ˆ Key Visualizations
1. **Hackathon Trends**: Most popular categories and deadlines.
2. **Internship Patterns**: Application trends and top companies.
3. **Job Insights**: Role popularity and impression patterns.
4. **Cross-Dataset Analysis**: Application correlations across datasets.

---

## ğŸ“œ Requirements
- Python 3.8 or higher
- Libraries:
  - `pandas`
  - `numpy`
  - `matplotlib`
  - `seaborn`
  - `scikit-learn`
  - `streamlit`
  - `plotly`
  - `wordcloud`
  - `jupyter`

Install using:
```bash
pip install -r requirements.txt
```

---

## ğŸ¤ Contributing
Contributions are welcome! Feel free to fork this repository and submit a pull request with your changes.

---

## `requirements.txt`

```plaintext
streamlit==1.22.0
pandas==1.5.3
numpy==1.23.5
matplotlib==3.6.2
seaborn==0.12.1
plotly==5.11.0
wordcloud==1.8.2.2
```

---

## `.gitignore`

```plaintext
*.csv
*.ipynb_checkpoints
__pycache__/
```
```
